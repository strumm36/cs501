# AI Reflection

* Include documentation on how and where you used AI to build this app. Where did AI misunderstand navigation?

My AI usage (ChatGPT) in this app was similar to the RecipeBrowser, to accelerate the development process but also to debug. I find it helpful when Android Studio sometimes doesn't know how to deal with an error sometimes ChatGPT will understand how to deal with it. Similarly to the RecipeBrowser, I started with the 2nd example from Lecture 5 as kind of a base to build the app off of, so lots of elements still remain from it including the comments. I also used AI to add elements to demonstrate the application that the instructions did not fully specify like functionality for adding a note to the list of notes to demonstrate the functional ViewModel, and also a back button to demonstrate the functionality of the back stack. The AI had a lot of trouble with the back button and the back stack, it seemed to not understand the errors between different requirements and types and its fixes would not work. I had to fix a massive bug with the back button where the current back stack was just always empty. I thought the instructions for this application were a little confusing, to be honest, they were quite vague and so it was hard to demonstrate certain functionalities without really knowing what had to be demonstrated. Generally, I used the AI as a bouncing off point whenever I got stuck or confused, to sort out all my thoughts. It was also quite helpful in accelerating the development of the screens.

In terms of documenting the back button behavior, the back button seems to work well. I treated the notes page like the home page and if you click the back button you'll go to where you were before, it works if you click calendar and then notes you'll go back to calendar.